<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Method</title>
    <link rel='stylesheet' type='text/css' media='screen' href="css/style.css">
    <link rel='stylesheet' type='text/css' media='screen' href='styles.css'> 
</head>
<body>
    <div id="contenedor">
       <header>
        <!--texto  de cabecera con degradado de fondo-->
            <p class="color_letra fuente1"> Method</p>
       </header>
       <nav><!--menú de navegación de la página-->
            <ul>
                <li class="menu"><a href="index.html">Introduction</a></li>
                <li class="menu"><a class="activo" href="#">Method</a></li>
                <li class="menu"><a href="#">Results</a></li>
                <li class="menu"><a href="#">Discussion</a></li>
            </ul>
        </nav><!--fin menú de navegación-->
        <article>
            <h1 class="color_letra fuente1">Method</h1>
           <cite>by <span class="rojo">Markus H. Hefter</span> <abbr title="et alumni">et al</abbr> · <time datetime="2023-03-10">March 10, 2023</time></cite>
            <p class="parrafo1">
            In recent years, COVID-19 policy measures massively affected university teaching. Seeking an effective and viable way to 
            transform their lecture material into asynchronous online settings, many lecturers relied on prerecorded video lectures.
            </p>
            <!--fin de la introducción-->
            <section>
                <h2 class="color_letra fuente1">Sample and Design</h2>
                <p>Three-hundred and seventeen teacher students at a German university participated in the online lecture. Hence, we have learning process data on N=317. Out of these 317 participants, 124 agreed to take part in the posttest immediately after the lecture. Therefore, our main sample that included data on learning outcomes comprised N=124 (73 females, 49 males). Random assignments to the experimental conditions were:</p>
                <ol type="a">
                    <li class="li_pag2">note prompts (notes condition, n=31)</li>
                    <li class="li_pag2">principle-based self-explanation prompts (principles condition, n=36)</li>
                    <li class="li_pag2">elaboration-based self-explanation prompts (elaborations condition, n=29)</li>
                    <li class="li_pag2">both principle and elaboration-based prompts (combined condition, n=28).</li>                       
                </ol>
                <p>Out of our main sample of 124 participants, 95 took part in the delayed posttest. These dropouts resulted in varying degrees of freedom (df) in the respective statistical analyses. Please see Table 1 for an overview on the conditions and number of participants.</p>
                <figure>
                    <a href="img/table1.png" target="_blank"><img src="img/table1.png" alt="Table 1: overview on the conditions and number of participants"></a>
                    <figcaption>Table 1: overview on the conditions and number of participants. Click to enlarge</figcaption>
                </figure>     
            </section>
            <section>
                <h2 class="color_letra fuente1">Procedures and materials</h2>
                <p>This study took place completely online during the summer and winter semesters of 2021/2022. The video lecture took place in the 9th week of the semester, and participants had 3 weeks to access the online lecture on our online platform via their own device’ web browser. After receiving the data protection information and providing informed consent, participants took the pretest on declarative knowledge and watched the lectures’ video clips.</p>
                <p>This lecture was identical for all our four experimental conditions and featured the topic Cognitive Apprenticeship (Collins et al). It was video-based and lasted roughly 40 min in total, showing the last author lecturing and presenting slides. We cut the lecture into six video clips. The first clip was an introduction of about 25 min. Then came four shorter clips lasting about 2 min each that focused on the four main lecture principles. These principles were the components of the Cognitive Apprenticeship the students should learn, namely</p>
                <ul>
                    <li class="li_img">Modelling</li>
                    <li class="li_img">Scaffolding and Fading</li>
                    <li class="li_img">Articulation and Reflection</li>
                    <li class="li_img">Exploration</li>                       
                </ul>
                <p>The lecture ended with a short outro clip of about 5 min. After each of the four clips about the main principles, a prompt according to the experimental condition was shown.</p>
            </section>
            <section>
                <h2 class="color_letra fuente1">Measures</h2>
                <h3 class="fuente1">Learning time</h3>
                <p>The online platform we used for the video lecture logged the time that participants spent viewing the four video clips and answering the prompts. The participants could take as much time as they wanted to answer the prompts. The time the participants spent watching the video clips was fixed, though, and the prompts only ever showed up, once the video had finished. Hence, learning time can actually be considered as the sole “prompt-answering” time.</p>

                <h3 class="fuente1">Declarative knowledge</h3>
                    
                    <div class="borde_izq"><!--inicio subsección-->
                    <p>To assess learning outcomes, we focused on declarative and conceptual knowledge. More specifically, declarative knowledge related to a short test comprising eight closed true-or-false items about the lecture’s main principles. Students could answer them with “true”, “false”, or “do not know.” Scoring for each item was one point for a right answer, minus one point for a wrong answer, and zero points for “do not know.” We summed up the score for all eight items to arrive at a total score on declarative knowledge. We carried out this test three times:</p>
                    <ol type="I">
                        <li class="li_pag2">right before the lecture (pretest)</li>
                        <li class="li_pag2">right after the lecture (immediate posttest)</li>
                        <li class="li_pag2">3 weeks later (delayed posttest)</li>
                    </ol>
                    </div><!--fin subsección-->

                 <h3 class="fuente1">Conceptual knowledge</h3>
                 <p>To assess deeper conceptual knowledge about the lecture’s main principles, we posed an open question: Please describe the main principles of the Cognitive Apprenticeship components. We rated participants’ answers on a scale from 0 (minimum) to 8 (maximum), giving up to two points for describing the principles of each the four components. Hence, to receive the maximum rating of eight all four components needed to be correctly described. We assessed conceptual knowledge right after the lecture (immediate posttest) and 3 weeks later (delayed posttest). The first author and a student research assistant were blind to the conditions and rated the data from 25 randomly selected participants.</p>
            </section>

            <section>
                <h2 class="color_letra fuente1">Learning processes</h2>
                <p>First, an <abbr title="Analysis of variance">ANOVA</abbr> revealed a large effect of prompt type on principle-based self-explanation quality. Figure 1 displays the results. To test our specific hypotheses that both principle-based and combined self-explanation prompts foster principle-based self-explanations, we used the following contrast weights assigned to the prompt types: notes: − 1; principles: 1; elaborations: − 1; combined: 1.</p>
                <figure>
                    <img src="img/fig1.webp" class="imagen" alt="Table 1: overview on the conditions and number of participants">
                    <figcaption class="cursiva">Table 1: overview on the conditions and number of participants</figcaption>
                </figure>
            </section>
            <section>
                <h2 class="color_letra fuente1">References</h2>
                <ul>
                    <li class="li_pag2"><span class="negrita">Benson, R.</span> (1988).<span class="cursiva"> Helping pupils overcome homework distractions. The Clearing House: A Journal of Educational Strategies, published in Issues and Ideas.</span><a class="negrita verde_claro" href="https://doi.org/10.1080/00098655.1988.10113974"> https://doi.org/10.1080/00098655.1988.10113974</a></li>
                    <li class="li_pag2"><span class="negrita">Berthold, K., Eysink, T. H. S., & Renkl, A.</span> (2009). <span class="cursiva">Assisting self-explanation prompts are more effective than open prompts when learning with multiple representations, published in Instructional Science .</span><a class="negrita verde_claro" href="https://doi.org/10.1007/s11251-008-9051-z"> https://doi.org/10.1007/s11251-008-9051-z</a></li>
                    <li class="li_pag2"><span class="negrita">Berthold, K., & Renkl, A.</span> (2009).<span class="cursiva"> Instructional aids to support a conceptual understanding of multiple representations, published in Journal of Educational Psychology.</span><a class="negrita verde_claro" href="https://doi.org/10.1037/a0013247"> https://doi.org/10.1037/a0013247</a></li>
                </ul>
            </section>
        </article>
        <footer>
            Texto extraído del artículo <span class="cursiva">Can prompts improve self-explaining an online video lecture? Yes, but do not disturb!</span>, publicado en la revista
            <a href="https://educationaltechnologyjournal.springeropen.com/">International Journal of Educational Technology in Higher Education</a>
        </footer>
    </div>
</body>